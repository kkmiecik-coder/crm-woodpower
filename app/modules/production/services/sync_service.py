# modules/production/services/sync_service.py
"""
Serwis synchronizacji z Baselinker dla modu≈Çu Production
========================================================

Implementuje automatycznƒÖ synchronizacjƒô zam√≥wie≈Ñ z API Baselinker:
- Pobieranie zam√≥wie≈Ñ ze statusami produkcyjnymi
- Rozbijanie zam√≥wie≈Ñ na pojedyncze produkty z nowym formatem ID
- Parsowanie nazw produkt√≥w i obliczanie priorytet√≥w
- Aktualizacja status√≥w w Baselinker po zako≈Ñczeniu produkcji
- Obs≈Çuga b≈Çƒôd√≥w i retry mechanism
- Szczeg√≥≈Çowe logowanie wszystkich operacji

Obs≈Çugiwane statusy Baselinker:
- 138619 (W produkcji - surowe)
- 148832 (W produkcji - olejowanie)  
- 148831 (W produkcji - bejcowanie)
- 148830 (W produkcji - lakierowanie)
- 155824 (Nowe - op≈Çacone)

Status docelowy po produkcji: 138623 (Uko≈Ñczone)

Autor: Konrad Kmiecik
Wersja: 1.2 (Finalna - z zabezpieczeniami)
Data: 2025-01-08
"""

import json
import math
import requests
from datetime import datetime, date, timedelta
from typing import Dict, Any, List, Optional, Tuple
from sqlalchemy import and_, or_
from sqlalchemy.exc import IntegrityError
from extensions import db
from modules.logging import get_structured_logger

logger = get_structured_logger('production.sync')

class SyncError(Exception):
    """WyjƒÖtek dla b≈Çƒôd√≥w synchronizacji"""
    pass

class BaselinkerSyncService:
    """
    Serwis synchronizacji z API Baselinker
    
    ZarzƒÖdza dwukierunkowym przep≈Çywem danych miƒôdzy systemem produkcyjnym
    a platformƒÖ Baselinker z obs≈ÇugƒÖ b≈Çƒôd√≥w i retry mechanism.
    """
    
    def __init__(self):
        """Inicjalizacja serwisu synchronizacji"""
        # Statusy Baselinker kt√≥re interesujƒÖ nas w synchronizacji
        self.source_statuses = [
            138619,  # W produkcji - surowe
            148832,  # W produkcji - olejowanie
            148831,  # W produkcji - bejcowanie  
            148830,  # W produkcji - lakierowanie
            155824   # Nowe - op≈Çacone
        ]
        
        # Status docelowy po uko≈Ñczeniu produkcji
        self.target_completed_status = 138623  # Uko≈Ñczone
        
        # Konfiguracja API
        self.api_endpoint = "https://api.baselinker.com/connector.php"
        self.api_key = None
        self.api_timeout = 30
        
        # Konfiguracja synchronizacji
        self.max_items_per_batch = 1000
        self.max_retries = 3
        self.retry_delay = 5  # sekund
        
        # Inicjalizacja konfiguracji
        self._load_config()
        
        logger.info("Inicjalizacja BaselinkerSyncService", extra={
            'source_statuses': self.source_statuses,
            'target_status': self.target_completed_status,
            'max_items_per_batch': self.max_items_per_batch
        })

    
    def _load_config(self):
        """≈Åaduje konfiguracjƒô z Flask app.config (zamiast bezpo≈õrednio z pliku)"""
        try:
            # POPRAWKA: U≈ºywaj current_app.config zamiast bezpo≈õredniego czytania pliku
            from flask import current_app
        
            # Pobierz konfiguracjƒô API Baselinker z Flask config
            api_config = current_app.config.get('API_BASELINKER', {})
            self.api_key = api_config.get('api_key')
            if api_config.get('endpoint'):
                self.api_endpoint = api_config['endpoint']
        
            logger.info("Za≈Çadowano konfiguracjƒô API Baselinker", extra={
                'api_key_present': bool(self.api_key),
                'endpoint': self.api_endpoint
            })
        
            # Sprawdzenie konfiguracji z modu≈Çu production
            try:
                from .config_service import get_config
            
                self.max_items_per_batch = get_config('MAX_SYNC_ITEMS_PER_BATCH', 1000)
                self.target_completed_status = get_config('BASELINKER_TARGET_STATUS_COMPLETED', 138623)
            
            except ImportError:
                logger.warning("Nie mo≈ºna za≈Çadowaƒá konfiguracji z ProductionConfigService")
        
            # Sprawdzenie czy klucz API zosta≈Ç za≈Çadowany
            if not self.api_key:
                logger.error("Brak klucza API Baselinker w konfiguracji")
                logger.error("Dostƒôpne klucze w current_app.config: %s", list(current_app.config.keys()))
            else:
                logger.info("Klucz API Baselinker za≈Çadowany pomy≈õlnie")
            
        except Exception as e:
            logger.error("B≈ÇƒÖd ≈Çadowania konfiguracji", extra={'error': str(e)})
        
            # FALLBACK: Je≈õli current_app nie jest dostƒôpne, spr√≥buj starej metody
            logger.warning("Pr√≥ba fallback z bezpo≈õrednim czytaniem pliku")
            try:
                import json
                import os
            
                config_path = os.path.join('app', 'config', 'core.json')
                if os.path.exists(config_path):
                    with open(config_path, 'r') as f:
                        config = json.load(f)
                        api_config = config.get('API_BASELINKER', {})
                        self.api_key = api_config.get('api_key')
                        if api_config.get('endpoint'):
                            self.api_endpoint = api_config['endpoint']
                    logger.info("Fallback: Za≈Çadowano konfiguracjƒô z pliku")
                else:
                    logger.error("Fallback: Plik konfiguracji nie istnieje: %s", config_path)
                
            except Exception as fallback_error:
                logger.error("Fallback r√≥wnie≈º siƒô nie powi√≥d≈Ç", extra={'error': str(fallback_error)})

    
    def sync_orders_from_baselinker(self, sync_type: str = 'cron_auto') -> Dict[str, Any]:
        """
        G≈Ç√≥wna metoda synchronizacji zam√≥wie≈Ñ z Baselinker
        
        Args:
            sync_type (str): Typ synchronizacji ('cron_auto' lub 'manual_trigger')
            
        Returns:
            Dict[str, Any]: Wyniki synchronizacji
        """
        sync_started_at = datetime.utcnow()
        
        # DODAJ: Wyczy≈õƒá cache ID generatora na poczƒÖtku sync
        from ..services.id_generator import ProductIDGenerator
        ProductIDGenerator.clear_order_cache()
        logger.info("Wyczyszczono cache generatora ID na poczƒÖtku synchronizacji")
    
        # Rozpoczƒôcie logowania synchronizacji
        sync_log = self._create_sync_log(sync_type, sync_started_at)
        
        try:
            logger.info("Rozpoczƒôcie synchronizacji Baselinker", extra={
                'sync_type': sync_type,
                'sync_log_id': sync_log.id if sync_log else None
            })
            
            # 1. Pobieranie zam√≥wie≈Ñ z Baselinker
            orders_data = self._fetch_orders_from_baselinker()
            if sync_log:
                sync_log.orders_fetched = len(orders_data)
            
            # 2. Przetwarzanie zam√≥wie≈Ñ na produkty
            processing_results = self._process_orders_to_products(orders_data)
            
            if sync_log:
                sync_log.products_created = processing_results['created']
                sync_log.products_updated = processing_results['updated'] 
                sync_log.products_skipped = processing_results['skipped']
                sync_log.error_count = processing_results['errors']
                sync_log.error_details = json.dumps(processing_results['error_details'])
            
            # 3. Aktualizacja priorytet√≥w dla nowych produkt√≥w
            self._update_product_priorities()
            
            # 4. Zako≈Ñczenie synchronizacji
            if sync_log:
                sync_log.mark_completed()
                db.session.commit()
            
            results = {
                'success': True,
                'sync_duration_seconds': sync_log.sync_duration_seconds if sync_log else 0,
                'orders_fetched': len(orders_data),
                'products_created': processing_results['created'],
                'products_updated': processing_results['updated'],
                'products_skipped': processing_results['skipped'],
                'error_count': processing_results['errors']
            }
            
            logger.info("Zako≈Ñczono synchronizacjƒô Baselinker", extra=results)
            return results
            
        except Exception as e:
            logger.error("B≈ÇƒÖd synchronizacji Baselinker", extra={
                'sync_type': sync_type,
                'error': str(e)
            })
            
            if sync_log:
                sync_log.sync_status = 'failed'
                sync_log.error_count = sync_log.error_count + 1 if sync_log.error_count else 1
                sync_log.error_details = json.dumps({'main_error': str(e)})
                sync_log.mark_completed()
                db.session.commit()
            
            return {
                'success': False,
                'error': str(e),
                'sync_duration_seconds': sync_log.sync_duration_seconds if sync_log else 0
            }
    
    def _create_sync_log(self, sync_type: str, sync_started_at: datetime) -> Optional['ProductionSyncLog']:
        """
        Tworzy rekord synchronizacji w bazie danych

        Args:
            sync_type (str): Typ synchronizacji
            sync_started_at (datetime): Czas rozpoczƒôcia

        Returns:
            Optional[ProductionSyncLog]: Rekord logu lub None przy b≈Çƒôdzie
        """
        try:
            from ..models import ProductionSyncLog

            sync_log = ProductionSyncLog(
                sync_type=sync_type,
                sync_started_at=sync_started_at,
                processed_status_ids=','.join(map(str, self.source_statuses))
            )

            db.session.add(sync_log)
            db.session.commit()

            return sync_log

        except Exception as e:
            logger.error("B≈ÇƒÖd tworzenia logu synchronizacji", extra={'error': str(e)})
            return None


    def manual_sync_with_filtering(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Rƒôczna synchronizacja z Baselinkerem z filtrowaniem produkt√≥w."""

        sync_started_at = datetime.utcnow()
        sync_log = self._create_sync_log('manual_trigger', sync_started_at)

        stats = {
            'pages_processed': 0,
            'orders_found': 0,
            'orders_matched_status': 0,
            'orders_processed': 0,
            'orders_skipped_existing': 0,
            'products_created': 0,
            'products_updated': 0,
            'products_skipped': 0,
            'errors_count': 0
        }
        error_details: List[Dict[str, Any]] = []
        log_entries: List[Dict[str, Any]] = []

        try:
            target_statuses_raw = params.get('target_statuses') or []
            target_statuses = {
                status for status in (
                    self._safe_int(value) for value in target_statuses_raw
                ) if status is not None
            }

            if not target_statuses:
                raise SyncError('Brak docelowych status√≥w zam√≥wie≈Ñ do synchronizacji.')

            try:
                period_days = int(params.get('period_days', 25))
            except (TypeError, ValueError):
                period_days = 25
            period_days = max(1, min(period_days, 90))

            try:
                limit_per_page = int(params.get('limit_per_page', 100))
            except (TypeError, ValueError):
                limit_per_page = 100
            limit_per_page = max(10, min(limit_per_page, 200))

            force_update = bool(params.get('force_update'))
            skip_validation = bool(params.get('skip_validation'))
            dry_run = bool(params.get('dry_run'))
            debug_mode = bool(params.get('debug_mode'))

            excluded_keywords = {
                str(keyword).lower().strip()
                for keyword in params.get('excluded_keywords', [])
                if isinstance(keyword, str) and keyword.strip()
            }

            if sync_log:
                sync_log.processed_status_ids = ','.join(map(str, sorted(target_statuses)))

            def add_log(message: str, level: str = 'info', **context: Any) -> None:
                timestamp = datetime.utcnow().isoformat()
                entry: Dict[str, Any] = {
                    'timestamp': timestamp,
                    'level': level,
                    'message': message
                }
                if context:
                    entry['context'] = context
                log_entries.append(entry)

                if level == 'error':
                    logger.error(message, extra={'context': 'manual_sync', **{f'ctx_{k}': v for k, v in context.items()}})
                elif level == 'warning':
                    logger.warning(message, extra={'context': 'manual_sync', **{f'ctx_{k}': v for k, v in context.items()}})
                elif level == 'debug':
                    if debug_mode:
                        logger.debug(message, extra={'context': 'manual_sync', **{f'ctx_{k}': v for k, v in context.items()}})
                else:
                    logger.info(message, extra={'context': 'manual_sync', **{f'ctx_{k}': v for k, v in context.items()}})

            add_log('Rozpoczynanie rƒôcznej synchronizacji z Baselinker.', 'info')
            add_log(
                'Parametry synchronizacji',
                'debug' if debug_mode else 'info',
                period_days=period_days,
                limit_per_page=limit_per_page,
                force_update=force_update,
                skip_validation=skip_validation,
                dry_run=dry_run,
                debug_mode=debug_mode,
                target_statuses=sorted(target_statuses)
            )

            date_to = datetime.utcnow()
            date_from = date_to - timedelta(days=period_days)
            add_log(
                f'Zakres synchronizacji: {date_from.date()} ‚Üí {date_to.date()}',
                'info'
            )

            from modules.reports.service import get_reports_service

            reports_service = get_reports_service()
            if not reports_service:
                raise SyncError('Nie mo≈ºna zainicjowaƒá serwisu raport√≥w Baselinker.')

            fetch_result = reports_service.fetch_orders_from_date_range(
                date_from=date_from,
                date_to=date_to,
                get_all_statuses=True,
                limit_per_page=limit_per_page
            )

            if not fetch_result.get('success'):
                raise SyncError(fetch_result.get('error', 'Nie uda≈Ço siƒô pobraƒá zam√≥wie≈Ñ z Baselinker.'))

            orders = fetch_result.get('orders', []) or []
            stats['orders_found'] = len(orders)
            stats['pages_processed'] = fetch_result.get('pages_processed') or 0
            if stats['pages_processed'] == 0 and stats['orders_found'] > 0:
                stats['pages_processed'] = max(1, math.ceil(stats['orders_found'] / max(limit_per_page, 1)))

            add_log(
                f'Pobrano {stats["orders_found"]} zam√≥wie≈Ñ (strony API: {stats["pages_processed"]}).',
                'info'
            )

            target_statuses_set = set(target_statuses)
            orders_after_status: List[Dict[str, Any]] = []
            for order in orders:
                status_value = self._safe_int(order.get('order_status_id') or order.get('status_id'))
                if status_value is None:
                    if debug_mode:
                        add_log(
                            'Pominiƒôto zam√≥wienie bez statusu.',
                            'debug',
                            order_id=order.get('order_id')
                        )
                    continue

                if status_value not in target_statuses_set:
                    continue

                orders_after_status.append(order)

            stats['orders_matched_status'] = len(orders_after_status)
            add_log(
                f'Do dalszego przetworzenia zakwalifikowano {stats["orders_matched_status"]} zam√≥wie≈Ñ.',
                'info'
            )

            reports_parser = None
            try:
                from modules.reports.parser import ProductNameParser as ReportsProductNameParser
                reports_parser = ReportsProductNameParser()
                if debug_mode:
                    add_log('Zainicjowano parser nazw produkt√≥w z modu≈Çu reports.', 'debug')
            except Exception as parser_error:
                add_log(
                    'Nie uda≈Ço siƒô zainicjowaƒá parsera nazw produkt√≥w z modu≈Çu reports. '
                    'U≈ºywane bƒôdzie podstawowe filtrowanie s≈Ç√≥w kluczowych.',
                    'warning'
                )
                logger.debug(
                    'Parser reports niedostƒôpny',
                    extra={'context': 'manual_sync', 'error': str(parser_error)}
                )

            excluded_product_types = {'suszenie', 'worek opa≈Çowy', 'tarcica', 'deska'}

            for order in orders_after_status:
                order_id_val = self._safe_int(order.get('order_id'))
                if order_id_val is None:
                    stats['errors_count'] += 1
                    error_details.append({'error': 'Brak identyfikatora zam√≥wienia', 'order': order})
                    add_log('Pominiƒôto zam√≥wienie bez identyfikatora.', 'error')
                    continue

                if not force_update and self._order_already_processed(order_id_val):
                    stats['orders_skipped_existing'] += 1
                    add_log(
                        f'Zam√≥wienie {order_id_val} by≈Ço ju≈º zsynchronizowane - pominiƒôto.',
                        'info'
                    )
                    continue

                if force_update and not dry_run:
                    try:
                        removed_count = self._delete_existing_items(order_id_val)
                        if removed_count:
                            stats['products_skipped'] += removed_count
                            add_log(
                                f'Usuniƒôto {removed_count} istniejƒÖcych pozycji zam√≥wienia {order_id_val}.',
                                'info'
                            )
                    except Exception as delete_error:
                        stats['errors_count'] += 1
                        error_details.append({'error': str(delete_error), 'order_id': order_id_val})
                        add_log(
                            f'Nie uda≈Ço siƒô usunƒÖƒá istniejƒÖcych pozycji zam√≥wienia {order_id_val}.',
                            'error'
                        )
                        continue

                products = order.get('products') or []
                if not products:
                    if debug_mode:
                        add_log(
                            f'Zam√≥wienie {order_id_val} nie zawiera produkt√≥w - pominiƒôto.',
                            'debug'
                        )
                    continue

                filtered_products: List[Dict[str, Any]] = []

                for product in products:
                    product_name_raw = product.get('name', '')
                    product_name = product_name_raw.strip() if isinstance(product_name_raw, str) else ''
                    if not product_name and skip_validation:
                        product_name = 'Produkt bez nazwy'

                    if not product_name and not skip_validation:
                        skipped_qty = self._coerce_quantity(product.get('quantity', 1))
                        stats['products_skipped'] += skipped_qty
                        add_log(
                            f'Pominiƒôto pozycjƒô bez nazwy w zam√≥wieniu {order_id_val}.',
                            'warning'
                        )
                        continue

                    quantity_value = self._coerce_quantity(product.get('quantity', 1))
                    if quantity_value <= 0:
                        if skip_validation:
                            quantity_value = 1
                        else:
                            stats['products_skipped'] += 1
                            if debug_mode:
                                add_log(
                                    f'Pominiƒôto pozycjƒô {product_name or product_name_raw} (nieprawid≈Çowa ilo≈õƒá).',
                                    'debug',
                                    order_id=order_id_val
                                )
                            continue

                    name_lower = product_name.lower()
                    if excluded_keywords and any(keyword in name_lower for keyword in excluded_keywords):
                        stats['products_skipped'] += quantity_value
                        if debug_mode:
                            add_log(
                                f"Wykluczono '{product_name}' na podstawie s≈Ç√≥w kluczowych.",
                                'debug',
                                order_id=order_id_val
                            )
                        continue

                    if reports_parser:
                        try:
                            parsed = reports_parser.parse_product_name(product_name)
                            product_type = (parsed.get('product_type') or '').lower()
                        except Exception as parse_error:
                            product_type = ''
                            if debug_mode:
                                add_log(
                                    f"B≈ÇƒÖd parsowania '{product_name}': {parse_error}",
                                    'debug',
                                    order_id=order_id_val
                                )
                        if product_type and product_type in excluded_product_types:
                            stats['products_skipped'] += quantity_value
                            if debug_mode:
                                add_log(
                                    f"Wykluczono '{product_name}' (typ: {product_type}).",
                                    'debug',
                                    order_id=order_id_val
                                )
                            continue

                    sanitized_product = dict(product)
                    sanitized_product['name'] = product_name if product_name else product.get('name', '')
                    sanitized_product['quantity'] = quantity_value
                    filtered_products.append(sanitized_product)

                if not filtered_products:
                    if debug_mode:
                        add_log(
                            f'Brak produkt√≥w do utworzenia dla zam√≥wienia {order_id_val} po filtrach.',
                            'debug'
                        )
                    continue

                if dry_run:
                    quantity_total = sum(prod.get('quantity', 0) or 0 for prod in filtered_products)
                    stats['products_created'] += quantity_total
                    stats['orders_processed'] += 1
                    add_log(
                        f"[DRY RUN] Zam√≥wienie {order_id_val}: {quantity_total} pozycji kwalifikuje siƒô do utworzenia.",
                        'info'
                    )
                    continue

                order_results = self._process_single_order(order, filtered_products, dry_run=False)
                stats['orders_processed'] += 1
                stats['products_created'] += order_results.get('created', 0)
                stats['products_updated'] += order_results.get('updated', 0)
                stats['errors_count'] += order_results.get('errors', 0)

                if order_results.get('error_details'):
                    error_details.extend(order_results['error_details'])
                    add_log(
                        f"Zam√≥wienie {order_id_val} zako≈Ñczone z b≈Çƒôdami ({len(order_results['error_details'])}).",
                        'warning'
                    )

                add_log(
                    f"Przetworzono zam√≥wienie {order_id_val} - utworzono {order_results.get('created', 0)} pozycji.",
                    'info'
                )

            add_log(
                f"Synchronizacja zako≈Ñczona. Zam√≥wienia przetworzone: {stats['orders_processed']},"
                f" utworzone produkty: {stats['products_created']}.",
                'info'
            )

            if sync_log:
                sync_log.orders_fetched = stats['orders_matched_status']
                sync_log.products_created = stats['products_created']
                sync_log.products_updated = stats['products_updated']
                sync_log.products_skipped = stats['products_skipped']
                sync_log.error_count = stats['errors_count']
                if error_details:
                    sync_log.error_details = json.dumps({'errors': error_details})
                sync_log.mark_completed()
                db.session.commit()

            sync_completed_at = datetime.utcnow()
            duration_seconds = int((sync_completed_at - sync_started_at).total_seconds())
            status_label = 'dry_run' if dry_run else ('partial' if stats['errors_count'] > 0 else 'completed')

            stats_payload = {
                'pages_processed': int(stats['pages_processed']),
                'orders_found': int(stats['orders_found']),
                'orders_matched': int(stats['orders_matched_status']),
                'orders_processed': int(stats['orders_processed']),
                'orders_skipped_existing': int(stats['orders_skipped_existing']),
                'products_created': int(stats['products_created']),
                'products_updated': int(stats['products_updated']),
                'products_skipped': int(stats['products_skipped']),
                'errors_count': int(stats['errors_count'])
            }

            response = {
                'success': True,
                'message': 'Synchronizacja Baselinker zako≈Ñczona pomy≈õlnie.',
                'data': {
                    'sync_id': f"manual_{sync_log.id}" if sync_log else f"manual_{int(sync_started_at.timestamp())}",
                    'status': status_label,
                    'started_at': sync_started_at.isoformat(),
                    'completed_at': sync_completed_at.isoformat(),
                    'duration_seconds': duration_seconds,
                    'options': {
                        'force_update': force_update,
                        'skip_validation': skip_validation,
                        'dry_run': dry_run,
                        'debug_mode': debug_mode,
                        'limit_per_page': limit_per_page,
                        'period_days': period_days,
                        'target_statuses': sorted(target_statuses),
                        'excluded_keywords': sorted(excluded_keywords)
                    },
                    'stats': stats_payload,
                    'log_entries': log_entries
                }
            }

            return response

        except SyncError as sync_error:
            logger.warning('Manual Baselinker sync validation error', extra={'error': str(sync_error)})
            if sync_log:
                sync_log.sync_status = 'failed'
                sync_log.error_count = (sync_log.error_count or 0) + 1
                sync_log.error_details = json.dumps({'error': str(sync_error), 'logs': log_entries[-20:]})
                sync_log.mark_completed()
                db.session.commit()

            add_log(str(sync_error), 'error')
            sync_completed_at = datetime.utcnow()
            stats_payload = {
                'pages_processed': int(stats['pages_processed']),
                'orders_found': int(stats['orders_found']),
                'orders_matched': int(stats['orders_matched_status']),
                'orders_processed': int(stats['orders_processed']),
                'orders_skipped_existing': int(stats['orders_skipped_existing']),
                'products_created': int(stats['products_created']),
                'products_updated': int(stats['products_updated']),
                'products_skipped': int(stats['products_skipped']),
                'errors_count': int(stats['errors_count'] + 1)
            }

            return {
                'success': False,
                'error': str(sync_error),
                'data': {
                    'status': 'failed',
                    'started_at': sync_started_at.isoformat(),
                    'completed_at': sync_completed_at.isoformat(),
                    'duration_seconds': int((sync_completed_at - sync_started_at).total_seconds()),
                    'stats': stats_payload,
                    'log_entries': log_entries
                }
            }

        except Exception as exc:
            logger.exception('Manual Baselinker sync unexpected error')
            if sync_log:
                sync_log.sync_status = 'failed'
                sync_log.error_count = (sync_log.error_count or 0) + 1
                sync_log.error_details = json.dumps({'error': str(exc), 'logs': log_entries[-20:]})
                sync_log.mark_completed()
                db.session.commit()

            add_log(str(exc), 'error')
            sync_completed_at = datetime.utcnow()
            stats_payload = {
                'pages_processed': int(stats['pages_processed']),
                'orders_found': int(stats['orders_found']),
                'orders_matched': int(stats['orders_matched_status']),
                'orders_processed': int(stats['orders_processed']),
                'orders_skipped_existing': int(stats['orders_skipped_existing']),
                'products_created': int(stats['products_created']),
                'products_updated': int(stats['products_updated']),
                'products_skipped': int(stats['products_skipped']),
                'errors_count': int(stats['errors_count'] + 1)
            }

            return {
                'success': False,
                'error': 'WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd podczas synchronizacji.',
                'data': {
                    'status': 'failed',
                    'started_at': sync_started_at.isoformat(),
                    'completed_at': sync_completed_at.isoformat(),
                    'duration_seconds': int((sync_completed_at - sync_started_at).total_seconds()),
                    'stats': stats_payload,
                    'log_entries': log_entries
                }
            }

    
    def _fetch_orders_from_baselinker(self) -> List[Dict[str, Any]]:
        """
        Pobiera zam√≥wienia z Baselinker API
        
        Returns:
            List[Dict[str, Any]]: Lista zam√≥wie≈Ñ z Baselinker
            
        Raises:
            SyncError: W przypadku b≈Çƒôdu komunikacji z API
        """
        if not self.api_key:
            raise SyncError("Brak klucza API Baselinker")
        
        all_orders = []
        
        for status_id in self.source_statuses:
            try:
                logger.debug("Pobieranie zam√≥wie≈Ñ dla statusu", extra={
                    'status_id': status_id
                })
                
                # Przygotowanie requestu do Baselinker
                request_data = {
                    'token': self.api_key,
                    'method': 'getOrders',
                    'parameters': json.dumps({
                        'status_id': status_id,
                        'get_unconfirmed_orders': True,
                        'date_confirmed_from': int((datetime.now() - timedelta(days=30)).timestamp()),
                        'date_limit': self.max_items_per_batch
                    })
                }
                
                # Wykonanie requestu z retry
                response_data = self._make_api_request(request_data)
                
                if response_data.get('status') == 'SUCCESS':
                    orders = response_data.get('orders', [])
                    all_orders.extend(orders)
                    
                    logger.debug("Pobrano zam√≥wienia dla statusu", extra={
                        'status_id': status_id,
                        'orders_count': len(orders)
                    })
                else:
                    error_msg = response_data.get('error_message', 'Unknown error')
                    logger.warning("B≈ÇƒÖd API dla statusu", extra={
                        'status_id': status_id,
                        'error': error_msg
                    })
                    
            except Exception as e:
                logger.error("B≈ÇƒÖd pobierania zam√≥wie≈Ñ dla statusu", extra={
                    'status_id': status_id,
                    'error': str(e)
                })
                continue
        
        logger.info("Pobrano wszystkie zam√≥wienia z Baselinker", extra={
            'total_orders': len(all_orders)
        })
        
        return all_orders
    
    def _make_api_request(self, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Wykonuje request do API Baselinker z retry mechanism
        
        Args:
            request_data (Dict[str, Any]): Dane requestu
            
        Returns:
            Dict[str, Any]: Odpowied≈∫ z API
            
        Raises:
            SyncError: W przypadku b≈Çƒôdu komunikacji
        """
        last_error = None
        
        for attempt in range(self.max_retries):
            try:
                logger.debug("Wykonywanie requestu do Baselinker", extra={
                    'attempt': attempt + 1,
                    'method': request_data.get('method')
                })
                
                response = requests.post(
                    self.api_endpoint,
                    data=request_data,
                    timeout=self.api_timeout,
                    headers={'Content-Type': 'application/x-www-form-urlencoded'}
                )
                
                response.raise_for_status()
                
                try:
                    response_data = response.json()
                    return response_data
                except json.JSONDecodeError as e:
                    raise SyncError(f"Nieprawid≈Çowa odpowied≈∫ JSON: {e}")
                    
            except requests.RequestException as e:
                last_error = e
                logger.warning("B≈ÇƒÖd requestu API", extra={
                    'attempt': attempt + 1,
                    'error': str(e)
                })
                
                if attempt < self.max_retries - 1:
                    import time
                    time.sleep(self.retry_delay * (attempt + 1))  # Exponential backoff
                
        raise SyncError(f"Nie uda≈Ço siƒô wykonaƒá requestu po {self.max_retries} pr√≥bach: {last_error}")
    
    def _process_orders_to_products(self, orders_data: List[Dict[str, Any]], dry_run: bool = False) -> Dict[str, Any]:
        """
        Wersja z debugowaniem
        """
        results = {
            'created': 0,
            'updated': 0,
            'skipped': 0,
            'errors': 0,
            'error_details': []
        }
        
        for order in orders_data:
            try:
                order_id = order.get('order_id')
                if not order_id:
                    results['errors'] += 1
                    continue
                
                # DEBUG stanu przed ka≈ºdym zam√≥wieniem
                self.debug_id_generator_state(order_id)
                
                # Sprawdzenie czy zam√≥wienie ju≈º istnieje
                if self._order_already_processed(order_id):
                    logger.info("‚è≠Ô∏è DEBUG: Zam√≥wienie ju≈º przetworzone - pomijam", extra={
                        'order_id': order_id
                    })
                    results['skipped'] += 1
                    continue
                
                products = order.get('products', [])
                if not products:
                    logger.debug("‚è≠Ô∏è DEBUG: Zam√≥wienie bez produkt√≥w", extra={'order_id': order_id})
                    results['skipped'] += 1
                    continue
                
                # U≈ªYJ nowej metody z pe≈Çnym debugowaniem
                order_results = self._process_single_order_with_full_debug(order, products, dry_run=dry_run)
                
                results['created'] += order_results['created']
                results['updated'] += order_results['updated']
                results['errors'] += order_results['errors']
                results['error_details'].extend(order_results['error_details'])
                
            except Exception as e:
                results['errors'] += 1
                results['error_details'].append({
                    'error': str(e),
                    'order_id': order.get('order_id', 'unknown')
                })
                logger.error("üö® DEBUG: B≈ÇƒÖd przetwarzania zam√≥wienia", extra={
                    'order_id': order.get('order_id'),
                    'error': str(e)
                })
        
        return results
    
    def _order_already_processed(self, baselinker_order_id: int) -> bool:
        """
        Sprawdza czy zam√≥wienie ju≈º zosta≈Ço przetworzone
        
        Args:
            baselinker_order_id (int): ID zam√≥wienia w Baselinker
            
        Returns:
            bool: True je≈õli zam√≥wienie ju≈º istnieje
        """
        try:
            from ..models import ProductionItem
            
            existing = ProductionItem.query.filter_by(
                baselinker_order_id=baselinker_order_id
            ).first()
            
            return existing is not None
            
        except Exception as e:
            logger.error("B≈ÇƒÖd sprawdzania istniejƒÖcego zam√≥wienia", extra={
                'order_id': baselinker_order_id,
                'error': str(e)
            })
            return False


    def _coerce_quantity(self, value: Any, default: int = 1) -> int:
        """Konwertuje warto≈õƒá quantity na bezpiecznƒÖ liczbƒô ca≈ÇkowitƒÖ."""
        try:
            if value is None:
                return default

            if isinstance(value, (int, float)):
                quantity = int(float(value))
            else:
                value_str = str(value).strip()
                if not value_str:
                    return default
                quantity = int(float(value_str.replace(',', '.')))

            if quantity <= 0:
                return default

            return quantity

        except (TypeError, ValueError):
            return default

    def _safe_int(self, value: Any) -> Optional[int]:
        """Bezpiecznie konwertuje warto≈õƒá na int lub zwraca None."""
        try:
            if value is None:
                return None

            if isinstance(value, (int, float)):
                converted = int(float(value))
            else:
                value_str = str(value).strip()
                if not value_str:
                    return None
                converted = int(float(value_str))

            return converted

        except (TypeError, ValueError):
            return None

    def _delete_existing_items(self, baselinker_order_id: int) -> int:
        """Usuwa istniejƒÖce produkty powiƒÖzane z zam√≥wieniem Baselinker."""
        from ..models import ProductionItem

        try:
            deleted_count = ProductionItem.query.filter_by(
                baselinker_order_id=baselinker_order_id
            ).delete()
            db.session.commit()
            return deleted_count or 0
        except Exception as exc:
            db.session.rollback()
            logger.error("B≈ÇƒÖd usuwania istniejƒÖcych produkt√≥w", extra={
                'order_id': baselinker_order_id,
                'error': str(exc)
            })
            raise

    
    def _process_single_order(self, order: Dict[str, Any], products: List[Dict[str, Any]], dry_run: bool = False) -> Dict[str, Any]:
        """
        Przetwarza pojedyncze zam√≥wienie na produkty z poprawnƒÖ logikƒÖ numerowania ID

        Args:
            order (Dict[str, Any]): Dane zam√≥wienia
            products (List[Dict[str, Any]]): Lista produkt√≥w w zam√≥wieniu
            dry_run (bool): Czy wykonaƒá przetwarzanie w trybie symulacji
        
        Returns:
            Dict[str, Any]: Wyniki przetwarzania zam√≥wienia
        """
        results = {
            'created': 0,
            'updated': 0,
            'errors': 0,
            'error_details': []
        }

        baselinker_order_id = order['order_id']

        try:
            from ..services.id_generator import ProductIDGenerator
            from ..services.parser_service import get_parser_service
            from ..services.priority_service import get_priority_calculator
            from ..models import ProductionItem
        
            logger.info("Przetwarzanie zam√≥wienia", extra={
                'baselinker_order_id': baselinker_order_id,
                'products_count': len(products)
            })
        
            # KROK 1: Przygotowanie wsp√≥lnych danych dla zam√≥wienia
            client_data = self._extract_client_data(order)
            deadline_date = self._calculate_deadline_date(order)
        
            # KROK 2: Policz ≈ÇƒÖcznƒÖ liczbƒô produkt√≥w (suma wszystkich quantity)
            total_products_count = 0
            for product in products:
                quantity = self._coerce_quantity(product.get('quantity', 1))
                total_products_count += quantity
        
            logger.debug("Policzono produkty w zam√≥wieniu", extra={
                'baselinker_order_id': baselinker_order_id,
                'product_items': len(products),
                'total_products_count': total_products_count
            })
        
            # KROK 3: Wygeneruj WSZYSTKIE ID dla zam√≥wienia NARAZ
            # To zapewnia jeden XXXXX dla ca≈Çego zam√≥wienia
            id_result = ProductIDGenerator.generate_product_id_for_order(
                baselinker_order_id, total_products_count
            )
            
            product_ids_list = id_result['product_ids']  # Lista wszystkich ID: ['25_00024_1', '25_00024_2', ...]
            internal_order_number = id_result['internal_order_number']  # '25_00024'
        
            logger.debug("Wygenerowano ID dla zam√≥wienia", extra={
                'baselinker_order_id': baselinker_order_id,
                'internal_order_number': internal_order_number,
                'total_ids_generated': len(product_ids_list),
                'first_id': product_ids_list[0] if product_ids_list else None,
                'last_id': product_ids_list[-1] if product_ids_list else None
            })
        
            # KROK 4: Przetw√≥rz produkty u≈ºywajƒÖc pre-wygenerowanych ID
            current_id_index = 0  # Indeks w li≈õcie product_ids_list
            parser = get_parser_service()
            priority_calc = get_priority_calculator()
        
            for product_index, product in enumerate(products):
                try:
                    product_name = product.get('name', '')
                    quantity = self._coerce_quantity(product.get('quantity', 1))
                    order_product_id = product.get('order_product_id')

                    logger.debug("Przetwarzanie produktu", extra={
                        'product_name': product_name[:50],
                        'quantity': quantity,
                        'order_product_id': order_product_id,
                        'product_index': product_index
                    })

                    # Dla ka≈ºdej sztuki w quantity - utw√≥rz osobny rekord
                    for qty_index in range(quantity):
                        try:
                            # Sprawd≈∫ czy nie wyszli≈õmy poza zakres wygenerowanych ID
                            if current_id_index >= len(product_ids_list):
                                raise Exception(f"Brak ID dla produktu na pozycji {current_id_index}")
                            
                            # U≈ºyj kolejnego ID z listy
                            product_id = product_ids_list[current_id_index]
                            current_id_index += 1
                            
                            # Parsowanie nazwy produktu (raz na product, nie na quantity)
                            if qty_index == 0:  # Parsuj tylko pierwszy raz
                                parsed_data = parser.parse_product_name(product_name)
                            
                            # Przygotowanie danych produktu
                            product_data = self._prepare_product_data_new(
                                order=order,
                                product=product,
                                product_id=product_id,
                                id_result=id_result,
                                parsed_data=parsed_data,
                                client_data=client_data,
                                deadline_date=deadline_date,
                                order_product_id=order_product_id,
                                sequence_number=current_id_index  # Numer w sekwencji zam√≥wienia
                            )
                            
                            # Obliczenie priorytetu
                            priority_score = priority_calc.calculate_priority(product_data)
                            product_data['priority_score'] = priority_score
                            
                            if not dry_run:
                                # Zapis do bazy danych
                                production_item = ProductionItem(**product_data)
                                db.session.add(production_item)
                            
                            results['created'] += 1
                            
                            logger.debug("Utworzono produkt", extra={
                                'product_id': product_id,
                                'sequence_in_order': current_id_index,
                                'qty_index': qty_index + 1,
                                'priority_score': priority_score
                            })
                        
                        except Exception as e:
                            results['errors'] += 1
                            results['error_details'].append({
                                'product_name': product_name,
                                'qty_index': qty_index + 1,
                                'sequence': current_id_index,
                                'error': str(e)
                            })
                            logger.error("B≈ÇƒÖd tworzenia produktu", extra={
                                'product_name': product_name,
                                'qty_index': qty_index + 1,
                                'sequence': current_id_index,
                                'baselinker_order_id': baselinker_order_id,
                                'error': str(e)
                            })
                            # Nie zwiƒôkszaj current_id_index przy b≈Çƒôdzie - ID zostanie "zmarnowane"
                            # ale numeracja pozostanie sp√≥jna
                    
                except Exception as e:
                    results['errors'] += 1
                    results['error_details'].append({
                        'product_name': product.get('name'),
                        'product_index': product_index,
                        'order_id': baselinker_order_id,
                        'error': str(e)
                    })
                    logger.error("B≈ÇƒÖd przetwarzania produktu", extra={
                        'product_name': product.get('name', ''),
                        'product_index': product_index,
                        'baselinker_order_id': baselinker_order_id,
                        'error': str(e)
                    })
        
            # KROK 5: Commit wszystkich produkt√≥w z zam√≥wienia
            if not dry_run:
                db.session.commit()
            
            logger.info("Zako≈Ñczono przetwarzanie zam√≥wienia", extra={
                'baselinker_order_id': baselinker_order_id,
                'created': results['created'],
                'errors': results['errors'],
                'internal_order_number': internal_order_number,
                'ids_used': current_id_index,
                'ids_generated': len(product_ids_list)
            })

        except Exception as e:
            if not dry_run:
                db.session.rollback()
            results['errors'] += 1
            results['error_details'].append({
                'error': str(e),
                'order_id': baselinker_order_id
            })
            logger.error("B≈ÇƒÖd przetwarzania zam√≥wienia", extra={
                'order_id': baselinker_order_id,
                'error': str(e)
            })

        return results

    def _prepare_product_data(self, order: Dict[str, Any], product: Dict[str, Any], id_result: Dict[str, Any], parsed_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Przygotowuje dane produktu do zapisania w bazie
        
        Args:
            order (Dict[str, Any]): Dane zam√≥wienia
            product (Dict[str, Any]): Dane produktu
            id_result (Dict[str, Any]): Wygenerowane ID
            parsed_data (Dict[str, Any]): Sparsowane dane nazwy
            
        Returns:
            Dict[str, Any]: Przygotowane dane produktu
        """
        # Podstawowe dane z ID generator
        product_data = {
            'short_product_id': id_result['product_id'],
            'internal_order_number': id_result['internal_order_number'],
            'product_sequence_in_order': id_result['sequence'],
            'baselinker_order_id': order['order_id'],
            'original_product_name': product.get('name', ''),
            'baselinker_status_id': order.get('order_status_id')
        }
        
        # Dane sparsowane z nazwy produktu
        if parsed_data:
            product_data.update({
                'parsed_wood_species': parsed_data.get('wood_species'),
                'parsed_technology': parsed_data.get('technology'),
                'parsed_wood_class': parsed_data.get('wood_class'),
                'parsed_length_cm': parsed_data.get('length_cm'),
                'parsed_width_cm': parsed_data.get('width_cm'),
                'parsed_thickness_cm': parsed_data.get('thickness_cm'),
                'parsed_finish_state': parsed_data.get('finish_state'),
                'volume_m3': parsed_data.get('volume_m3')
            })
        
        # Dane finansowe
        try:
            unit_price = float(product.get('price_brutto', 0)) * 0.81  # Szacunkowa konwersja na netto
            product_data.update({
                'unit_price_net': unit_price,
                'total_value_net': unit_price  # Jedna sztuka
            })
        except (ValueError, TypeError):
            pass
        
        # Deadline (domy≈õlnie 14 dni od dzisiaj)
        try:
            from .config_service import get_config
            default_days = get_config('DEADLINE_DEFAULT_DAYS', 14)
            product_data['deadline_date'] = date.today() + timedelta(days=default_days)
        except:
            product_data['deadline_date'] = date.today() + timedelta(days=14)
        
        # Metadata
        product_data.update({
            'sync_source': 'baselinker_auto',
            'current_status': 'czeka_na_wyciecie'  # Domy≈õlny status poczƒÖtkowy
        })
        
        return product_data

    def _prepare_product_data_new(
        self, 
        order: Dict[str, Any], 
        product: Dict[str, Any], 
        product_id: str,
        id_result: Dict[str, Any], 
        parsed_data: Dict[str, Any],
        client_data: Dict[str, str],
        deadline_date: date,
        order_product_id: Any,
        sequence_number: int) -> Dict[str, Any]:
        """
        Przygotowuje dane produktu do zapisania w bazie - POPRAWIONA WERSJA
        
        Args:
            order: Dane zam√≥wienia z Baselinker
            product: Dane produktu z Baselinker  
            product_id: Wygenerowany short_product_id (np. '25_00024_3')
            id_result: Wynik generowania ID
            parsed_data: Sparsowane dane nazwy produktu
            client_data: Dane klienta
            deadline_date: Obliczona data deadline
            order_product_id: ID produktu w zam√≥wieniu z Baselinker
            sequence_number: Numer sekwencyjny w zam√≥wieniu (1, 2, 3, ...)
        
        Returns:
            Dict[str, Any]: Przygotowane dane produktu
        """

        # Podstawowe dane z ID generator
        product_data = {
            'short_product_id': product_id,
            'internal_order_number': id_result['internal_order_number'],
            'product_sequence_in_order': sequence_number,
            'baselinker_order_id': order['order_id'],
            'baselinker_product_id': str(order_product_id) if order_product_id else None,
            'original_product_name': product.get('name', ''),
            'baselinker_status_id': order.get('order_status_id'),
        
            # Dane klienta
            'client_name': client_data['client_name'],
            'client_email': client_data['client_email'],  
            'client_phone': client_data['client_phone'],
            'delivery_address': client_data['delivery_address'],
        
            # Deadline
            'deadline_date': deadline_date,
        
            # Status poczƒÖtkowy
            'current_status': 'czeka_na_wyciecie',
            'sync_source': 'baselinker_auto'
        }

        # Dane sparsowane z nazwy produktu
        if parsed_data:
            product_data.update({
                'parsed_wood_species': parsed_data.get('wood_species'),
                'parsed_technology': parsed_data.get('technology'),
                'parsed_wood_class': parsed_data.get('wood_class'),
                'parsed_length_cm': parsed_data.get('length_cm'),
                'parsed_width_cm': parsed_data.get('width_cm'),
                'parsed_thickness_cm': parsed_data.get('thickness_cm'),
                'parsed_finish_state': parsed_data.get('finish_state'),
                'volume_m3': parsed_data.get('volume_m3')
            })

        # Dane finansowe z produktu Baselinker
        try:
            price_brutto = float(product.get('price_brutto', 0))
            tax_rate = float(product.get('tax_rate', 23))
        
            # Oblicz cenƒô netto na JEDNƒÑ SZTUKƒò
            price_netto = price_brutto / (1 + tax_rate/100) if tax_rate > 0 else price_brutto
            
            # WA≈ªNE: Cena per sztuka, nie per quantity ca≈Çkowite
            # Je≈õli quantity=3, to ka≈ºdy z 3 rekord√≥w ma cenƒô za 1 sztukƒô
            product_quantity = self._coerce_quantity(product.get('quantity', 1))
            unit_price = price_netto / product_quantity if product_quantity > 0 else price_netto
        
            product_data.update({
                'unit_price_net': round(unit_price, 2),
                'total_value_net': round(unit_price, 2)  # Jeden rekord = jedna sztuka
            })
        except (ValueError, TypeError) as e:
            logger.warning("B≈ÇƒÖd obliczania cen produktu", extra={
                'product_name': product.get('name', '')[:50],
                'price_brutto': product.get('price_brutto'),
                'error': str(e)
            })
            product_data.update({
                'unit_price_net': 0,
                'total_value_net': 0
            })

        return product_data
    
    def _update_product_priorities(self):
        """
        Aktualizuje priorytety dla nowych produkt√≥w
        """
        try:
            from ..models import ProductionItem
            from ..services.priority_service import get_priority_calculator
            
            priority_calc = get_priority_calculator()
            if not priority_calc:
                logger.warning("Brak kalkulatora priorytet√≥w")
                return
            
            # Znajd≈∫ produkty bez ustawionego priorytetu
            products_to_update = ProductionItem.query.filter(
                ProductionItem.priority_score == 100,  # Domy≈õlny priorytet
                ProductionItem.current_status != 'spakowane'
            ).limit(100).all()  # Limit dla wydajno≈õci
            
            updated_count = 0
            for product in products_to_update:
                try:
                    # Przygotowanie danych do obliczenia priorytetu
                    product_data = {
                        'deadline_date': product.deadline_date,
                        'total_value_net': float(product.total_value_net or 0),
                        'volume_m3': float(product.volume_m3 or 0),
                        'created_at': product.created_at,
                        'wood_class': product.parsed_wood_class
                    }
                    
                    # Obliczenie nowego priorytetu
                    new_priority = priority_calc.calculate_priority(product_data)
                    
                    if new_priority != product.priority_score:
                        product.priority_score = new_priority
                        product.updated_at = datetime.utcnow()
                        updated_count += 1
                        
                except Exception as e:
                    logger.warning("B≈ÇƒÖd aktualizacji priorytetu produktu", extra={
                        'product_id': product.short_product_id,
                        'error': str(e)
                    })
            
            if updated_count > 0:
                db.session.commit()
                logger.info("Zaktualizowano priorytety produkt√≥w", extra={
                    'updated_count': updated_count
                })
                
        except Exception as e:
            logger.error("B≈ÇƒÖd aktualizacji priorytet√≥w", extra={'error': str(e)})
    
    def update_order_status_in_baselinker(self, internal_order_number: str) -> bool:
        """
        Aktualizuje status zam√≥wienia w Baselinker po zako≈Ñczeniu produkcji
        
        Args:
            internal_order_number (str): Numer zam√≥wienia wewnƒôtrznego (np. 25_05248)
            
        Returns:
            bool: True je≈õli aktualizacja siƒô powiod≈Ça
        """
        try:
            from ..models import ProductionItem
            
            # Znajd≈∫ wszystkie produkty z tego zam√≥wienia
            products = ProductionItem.query.filter_by(
                internal_order_number=internal_order_number
            ).all()
            
            if not products:
                logger.warning("Nie znaleziono produkt√≥w dla zam√≥wienia", extra={
                    'internal_order_number': internal_order_number
                })
                return False
            
            # Sprawd≈∫ czy wszystkie produkty sƒÖ spakowane
            all_packed = all(p.current_status == 'spakowane' for p in products)
            if not all_packed:
                logger.info("Nie wszystkie produkty sƒÖ spakowane", extra={
                    'internal_order_number': internal_order_number,
                    'packed_count': sum(1 for p in products if p.current_status == 'spakowane'),
                    'total_count': len(products)
                })
                return False
            
            # Pobierz baselinker_order_id
            baselinker_order_id = products[0].baselinker_order_id
            
            # Aktualizuj status w Baselinker
            return self._update_baselinker_order_status(baselinker_order_id, self.target_completed_status)
            
        except Exception as e:
            logger.error("B≈ÇƒÖd aktualizacji statusu w Baselinker", extra={
                'internal_order_number': internal_order_number,
                'error': str(e)
            })
            return False
    
    def _update_baselinker_order_status(self, baselinker_order_id: int, new_status_id: int) -> bool:
        """
        Aktualizuje status konkretnego zam√≥wienia w Baselinker
        
        Args:
            baselinker_order_id (int): ID zam√≥wienia w Baselinker
            new_status_id (int): Nowy status ID
            
        Returns:
            bool: True je≈õli aktualizacja siƒô powiod≈Ça
        """
        if not self.api_key:
            logger.error("Brak klucza API Baselinker dla aktualizacji statusu")
            return False
        
        try:
            request_data = {
                'token': self.api_key,
                'method': 'setOrderStatus',
                'parameters': json.dumps({
                    'order_id': baselinker_order_id,
                    'status_id': new_status_id
                })
            }
            
            response_data = self._make_api_request(request_data)
            
            if response_data.get('status') == 'SUCCESS':
                logger.info("Zaktualizowano status zam√≥wienia w Baselinker", extra={
                    'baselinker_order_id': baselinker_order_id,
                    'new_status_id': new_status_id
                })
                return True
            else:
                error_msg = response_data.get('error_message', 'Unknown error')
                logger.error("B≈ÇƒÖd aktualizacji statusu w Baselinker", extra={
                    'baselinker_order_id': baselinker_order_id,
                    'error': error_msg
                })
                return False
                
        except Exception as e:
            logger.error("B≈ÇƒÖd komunikacji z Baselinker przy aktualizacji statusu", extra={
                'baselinker_order_id': baselinker_order_id,
                'error': str(e)
            })
            return False
    
    def get_sync_status(self) -> Dict[str, Any]:
        """
        Pobiera status synchronizacji
        
        Returns:
            Dict[str, Any]: Informacje o statusie sync
        """
        try:
            from ..models import ProductionSyncLog
            
            # Ostatnia synchronizacja
            last_sync = ProductionSyncLog.query.order_by(
                ProductionSyncLog.sync_started_at.desc()
            ).first()
            
            # Synchronizacja w toku
            running_sync = ProductionSyncLog.query.filter_by(
                sync_status='running'
            ).first()
            
            # Statystyki ostatnich 24h
            since_24h = datetime.utcnow() - timedelta(hours=24)
            recent_syncs = ProductionSyncLog.query.filter(
                ProductionSyncLog.sync_started_at >= since_24h
            ).all()
            
            return {
                'sync_enabled': bool(self.api_key),
                'is_running': running_sync is not None,
                'last_sync': {
                    'timestamp': last_sync.sync_started_at.isoformat() if last_sync else None,
                    'status': last_sync.sync_status if last_sync else None,
                    'duration_seconds': last_sync.sync_duration_seconds if last_sync else None,
                    'products_created': last_sync.products_created if last_sync else 0,
                    'error_count': last_sync.error_count if last_sync else 0
                } if last_sync else None,
                'recent_stats': {
                    'syncs_count': len(recent_syncs),
                    'success_count': len([s for s in recent_syncs if s.sync_status == 'completed']),
                    'failed_count': len([s for s in recent_syncs if s.sync_status == 'failed']),
                    'total_products_created': sum(s.products_created or 0 for s in recent_syncs),
                    'total_errors': sum(s.error_count or 0 for s in recent_syncs)
                }
            }
            
        except Exception as e:
            logger.error("B≈ÇƒÖd pobierania statusu synchronizacji", extra={'error': str(e)})
            return {
                'sync_enabled': bool(self.api_key),
                'is_running': False,
                'error': str(e)
            }
    
    def cleanup_old_sync_logs(self, days_to_keep: int = 30):
        """
        Czy≈õci stare logi synchronizacji
        
        Args:
            days_to_keep (int): Liczba dni do zachowania
        """
        try:
            from ..models import ProductionSyncLog
            
            cutoff_date = datetime.utcnow() - timedelta(days=days_to_keep)
            
            deleted_count = ProductionSyncLog.query.filter(
                ProductionSyncLog.sync_started_at < cutoff_date
            ).delete()
            
            db.session.commit()
            
            logger.info("Wyczyszczono stare logi synchronizacji", extra={
                'deleted_count': deleted_count,
                'days_to_keep': days_to_keep
            })
            
        except Exception as e:
            db.session.rollback()
            logger.error("B≈ÇƒÖd czyszczenia log√≥w synchronizacji", extra={
                'error': str(e)
            })

    def update_order_status(self, internal_order_number: str) -> bool:
        """
        Alias dla update_order_status_in_baselinker dla zgodno≈õci z testami
    
        Args:
            internal_order_number (str): Numer zam√≥wienia wewnƒôtrznego
        
        Returns:
            bool: True je≈õli aktualizacja siƒô powiod≈Ça
        """
        return self.update_order_status_in_baselinker(internal_order_number)

    def _extract_client_data(self, order: Dict[str, Any]) -> Dict[str, str]:
        """
        WyciƒÖga dane klienta w hierarchii:
        delivery_fullname > invoice_fullname > user_login > email > phone
        """
        client_name = (
            order.get('delivery_fullname') or
            order.get('invoice_fullname') or 
            order.get('user_login') or
            order.get('email') or
            order.get('phone') or
            'Nieznany klient'
        )
    
        # Skr√≥ƒá nazwƒô klienta do maksymalnie 255 znak√≥w (limit bazy danych)
        if len(client_name) > 255:
            client_name = client_name[:252] + "..."
    
        # Przygotuj adres dostawy
        delivery_parts = [
            order.get('delivery_address', '').strip(),
            order.get('delivery_city', '').strip(),
            order.get('delivery_postcode', '').strip()
        ]
        delivery_address = ' '.join(part for part in delivery_parts if part)
    
        return {
            'client_name': client_name,
            'client_email': order.get('email', ''),
            'client_phone': order.get('phone', ''),
            'delivery_address': delivery_address
        }

    def _calculate_deadline_date(self, order: Dict[str, Any]) -> datetime.date:
        """
        Oblicza deadline na podstawie date_confirmed + konfigurowalne dni robocze
        """
        try:
            from ..services.config_service import get_config_service
            from datetime import timedelta
        
            date_confirmed_timestamp = order.get('date_confirmed')
            if not date_confirmed_timestamp:
                # Fallback: data dzisiejsza
                base_date = datetime.now().date()
                logger.warning("Brak date_confirmed w zam√≥wieniu, u≈ºywam daty dzisiejszej", extra={
                    'order_id': order.get('order_id')
                })
            else:
                # Konwersja timestamp Unix na date
                base_date = datetime.fromtimestamp(int(date_confirmed_timestamp)).date()
        
            # Pobierz konfigurowalne dni robocze (zapisane raz na poczƒÖtku sync)
            if not hasattr(self, '_cached_deadline_days'):
                config_service = get_config_service()
                self._cached_deadline_days = int(config_service.get_config('DEADLINE_DEFAULT_DAYS', '14'))
        
            # Oblicz deadline pomijajƒÖc weekendy
            deadline_date = self._add_business_days(base_date, self._cached_deadline_days)
        
            logger.debug("Obliczono deadline", extra={
                'order_id': order.get('order_id'),
                'date_confirmed': base_date.isoformat() if base_date else None,
                'deadline_days': self._cached_deadline_days,
                'calculated_deadline': deadline_date.isoformat()
            })
        
            return deadline_date
        
        except Exception as e:
            logger.error("B≈ÇƒÖd obliczania deadline", extra={
                'order_id': order.get('order_id'),
                'error': str(e)
            })
            # Fallback: dzisiejsza data + 14 dni roboczych
            return self._add_business_days(datetime.now().date(), 14)

    def _add_business_days(self, start_date: date, business_days: int) -> date:
        """Dodaje dni robocze pomijajƒÖc weekendy (sobota=5, niedziela=6)"""
        from datetime import timedelta
    
        current_date = start_date
        days_added = 0
    
        while days_added < business_days:
            current_date += timedelta(days=1)
            # Weekday: Poniedzia≈Çek=0, Wtorek=1, ..., Sobota=5, Niedziela=6
            if current_date.weekday() < 5:  # 0-4 = Poniedzia≈Çek-PiƒÖtek
                days_added += 1
            
        return current_date
    
    def debug_id_generator_state(self, baselinker_order_id: int):
        """Debug stanu ID generatora"""
        from ..services.id_generator import ProductIDGenerator
        
        logger.info("üîç DEBUG: Stan ID generatora", extra={
            'baselinker_order_id': baselinker_order_id,
            'cache_size': len(ProductIDGenerator._order_mapping_cache),
            'cache_contents': dict(ProductIDGenerator._order_mapping_cache)
        })
        
        # Sprawd≈∫ aktualny licznik w bazie
        current_counter = ProductIDGenerator.get_current_counter_for_year()
        logger.info("üîç DEBUG: Licznik w bazie danych", extra={
            'current_counter': current_counter
        })
    

    def _process_single_order_with_full_debug(self, order: Dict[str, Any], products: List[Dict[str, Any]], dry_run: bool = False) -> Dict[str, Any]:
        """
        Wersja _process_single_order z pe≈Çnym debugowaniem
        """
        results = {
            'created': 0,
            'updated': 0,
            'errors': 0,
            'error_details': []
        }

        baselinker_order_id = order['order_id']
        
        logger.info("üîç DEBUG: Rozpoczƒôcie przetwarzania zam√≥wienia", extra={
            'baselinker_order_id': baselinker_order_id,
            'products_count': len(products),
            'dry_run': dry_run
        })

        try:
            from ..services.id_generator import ProductIDGenerator
            from ..services.parser_service import get_parser_service
            from ..services.priority_service import get_priority_calculator
            from ..models import ProductionItem

            # DEBUG: Sprawd≈∫ stan bazy przed rozpoczƒôciem
            existing_count = ProductionItem.query.count()
            logger.info("üîç DEBUG: Stan bazy przed przetwarzaniem", extra={
                'total_records_in_db': existing_count,
                'baselinker_order_id': baselinker_order_id
            })
            
            # DEBUG: Sprawd≈∫ czy to zam√≥wienie ju≈º istnieje
            existing_for_order = ProductionItem.query.filter_by(
                baselinker_order_id=baselinker_order_id
            ).all()
            
            if existing_for_order:
                logger.warning("üö® DEBUG: Zam√≥wienie ju≈º istnieje w bazie!", extra={
                    'baselinker_order_id': baselinker_order_id,
                    'existing_records': len(existing_for_order),
                    'existing_ids': [item.short_product_id for item in existing_for_order]
                })
                # Wyjd≈∫ z funkcji, nie przetwarzaj ponownie
                return results

            # KROK 1: Przygotowanie wsp√≥lnych danych dla zam√≥wienia
            client_data = self._extract_client_data(order)
            deadline_date = self._calculate_deadline_date(order)

            # KROK 2: DEBUG - Szczeg√≥≈Çowa analiza produkt√≥w
            logger.info("üîç DEBUG: Analiza produkt√≥w w zam√≥wieniu", extra={
                'baselinker_order_id': baselinker_order_id
            })
            
            total_products_count = 0
            products_breakdown = []
            
            for i, product in enumerate(products):
                quantity = self._coerce_quantity(product.get('quantity', 1))
                total_products_count += quantity
                
                product_breakdown = {
                    'index': i,
                    'name': product.get('name', '')[:50],
                    'quantity': quantity,
                    'baselinker_product_id': product.get('order_product_id')
                }
                products_breakdown.append(product_breakdown)
                
                logger.info("üîç DEBUG: Produkt w zam√≥wieniu", extra={
                    'baselinker_order_id': baselinker_order_id,
                    'product_index': i,
                    'product_name': product.get('name', '')[:50],
                    'quantity': quantity,
                    'baselinker_product_id': product.get('order_product_id')
                })

            logger.info("üîç DEBUG: Podsumowanie produkt√≥w", extra={
                'baselinker_order_id': baselinker_order_id,
                'product_items_count': len(products),
                'total_products_count': total_products_count,
                'products_breakdown': products_breakdown
            })

            # KROK 3: Generowanie ID
            logger.info("üîç DEBUG: Przed generowaniem ID", extra={
                'baselinker_order_id': baselinker_order_id,
                'total_products_count': total_products_count
            })
            
            id_result = ProductIDGenerator.generate_product_id_for_order(
                baselinker_order_id, total_products_count
            )
            
            logger.info("üîç DEBUG: Po wygenerowaniu ID", extra={
                'baselinker_order_id': baselinker_order_id,
                'internal_order_number': id_result['internal_order_number'],
                'generated_ids_count': len(id_result['product_ids']),
                'first_id': id_result['product_ids'][0] if id_result['product_ids'] else None,
                'last_id': id_result['product_ids'][-1] if id_result['product_ids'] else None,
                'all_generated_ids': id_result['product_ids']
            })

            # KROK 4: Sprawdzenie unikalno≈õci przed wstawieniem
            logger.info("üîç DEBUG: Sprawdzanie unikalno≈õci wygenerowanych ID", extra={
                'baselinker_order_id': baselinker_order_id
            })
            
            for product_id in id_result['product_ids']:
                existing = ProductionItem.query.filter_by(short_product_id=product_id).first()
                if existing:
                    logger.error("üö® DEBUG: KONFLIKT! Wygenerowany ID ju≈º istnieje!", extra={
                        'baselinker_order_id': baselinker_order_id,
                        'conflicting_id': product_id,
                        'existing_record_id': existing.id,
                        'existing_order_id': existing.baselinker_order_id
                    })
                    results['errors'] += 1
                    results['error_details'].append({
                        'error': f'ID {product_id} ju≈º istnieje',
                        'conflicting_id': product_id
                    })
                    return results

            logger.info("‚úÖ DEBUG: Wszystkie wygenerowane ID sƒÖ unikalne", extra={
                'baselinker_order_id': baselinker_order_id
            })

            # KROK 5: Przetwarzanie produkt√≥w
            current_id_index = 0
            parser = get_parser_service()
            priority_calc = get_priority_calculator()
            
            prepared_items = []  # Lista do zbiorczego commit

            for product_index, product in enumerate(products):
                try:
                    product_name = product.get('name', '')
                    quantity = self._coerce_quantity(product.get('quantity', 1))
                    order_product_id = product.get('order_product_id')

                    logger.info("üîç DEBUG: Przetwarzanie produktu", extra={
                        'baselinker_order_id': baselinker_order_id,
                        'product_index': product_index,
                        'product_name': product_name[:50],
                        'quantity': quantity,
                        'current_id_index': current_id_index
                    })

                    # Parsowanie nazwy produktu (raz na produkt)
                    parsed_data = parser.parse_product_name(product_name)

                    # Dla ka≈ºdej sztuki w quantity
                    for qty_index in range(quantity):
                        try:
                            if current_id_index >= len(id_result['product_ids']):
                                raise Exception(f"Brak ID dla pozycji {current_id_index}")
                            
                            product_id = id_result['product_ids'][current_id_index]
                            current_id_index += 1

                            logger.info("üîç DEBUG: Tworzenie rekordu produktu", extra={
                                'baselinker_order_id': baselinker_order_id,
                                'product_id': product_id,
                                'qty_index': qty_index + 1,
                                'sequence_number': current_id_index
                            })

                            # Przygotowanie danych produktu
                            product_data = self._prepare_product_data_new(
                                order=order,
                                product=product,
                                product_id=product_id,
                                id_result=id_result,
                                parsed_data=parsed_data,
                                client_data=client_data,
                                deadline_date=deadline_date,
                                order_product_id=order_product_id,
                                sequence_number=current_id_index
                            )

                            # Obliczenie priorytetu
                            priority_score = priority_calc.calculate_priority(product_data)
                            product_data['priority_score'] = priority_score

                            if not dry_run:
                                # Przygotuj obiekt ale nie commituj jeszcze
                                production_item = ProductionItem(**product_data)
                                prepared_items.append(production_item)
                                
                                logger.info("üîç DEBUG: Przygotowano rekord do wstawienia", extra={
                                    'baselinker_order_id': baselinker_order_id,
                                    'product_id': product_id,
                                    'prepared_items_count': len(prepared_items)
                                })

                            results['created'] += 1

                        except Exception as e:
                            results['errors'] += 1
                            results['error_details'].append({
                                'product_name': product_name,
                                'qty_index': qty_index + 1,
                                'sequence': current_id_index,
                                'error': str(e)
                            })
                            logger.error("üö® DEBUG: B≈ÇƒÖd tworzenia produktu", extra={
                                'baselinker_order_id': baselinker_order_id,
                                'product_name': product_name[:50],
                                'qty_index': qty_index + 1,
                                'error': str(e)
                            })

                except Exception as e:
                    results['errors'] += 1
                    results['error_details'].append({
                        'product_name': product.get('name'),
                        'product_index': product_index,
                        'error': str(e)
                    })

            # KROK 6: Zbiorczy commit wszystkich rekord√≥w
            if not dry_run and prepared_items:
                logger.info("üîç DEBUG: Rozpoczƒôcie zbiorczego commit", extra={
                    'baselinker_order_id': baselinker_order_id,
                    'items_to_commit': len(prepared_items)
                })
                
                try:
                    # Dodaj wszystkie rekordy do sesji
                    for item in prepared_items:
                        db.session.add(item)
                    
                    # Commit wszystkich naraz
                    db.session.commit()
                    
                    logger.info("‚úÖ DEBUG: Zbiorczy commit zako≈Ñczony pomy≈õlnie", extra={
                        'baselinker_order_id': baselinker_order_id,
                        'committed_items': len(prepared_items)
                    })
                    
                    # Sprawd≈∫ stan po commit
                    final_count = ProductionItem.query.count()
                    logger.info("üîç DEBUG: Stan bazy po commit", extra={
                        'baselinker_order_id': baselinker_order_id,
                        'total_records_now': final_count
                    })
                    
                except Exception as e:
                    db.session.rollback()
                    logger.error("üö® DEBUG: B≈ÇƒÖd zbiorczego commit", extra={
                        'baselinker_order_id': baselinker_order_id,
                        'error': str(e),
                        'items_attempted': len(prepared_items)
                    })
                    
                    # Sprawd≈∫ kt√≥ry rekord powoduje problem
                    for i, item in enumerate(prepared_items):
                        existing = ProductionItem.query.filter_by(
                            short_product_id=item.short_product_id
                        ).first()
                        if existing:
                            logger.error("üö® DEBUG: Konflikt przy wstawianiu", extra={
                                'item_index': i,
                                'conflicting_id': item.short_product_id,
                                'existing_record': existing.id
                            })
                    
                    results['errors'] = len(prepared_items)
                    results['created'] = 0

            logger.info("üîç DEBUG: Zako≈Ñczenie przetwarzania zam√≥wienia", extra={
                'baselinker_order_id': baselinker_order_id,
                'created': results['created'],
                'errors': results['errors']
            })

        except Exception as e:
            if not dry_run:
                db.session.rollback()
            results['errors'] += 1
            results['error_details'].append({
                'error': str(e),
                'order_id': baselinker_order_id
            })
            logger.error("üö® DEBUG: B≈ÇƒÖd g≈Ç√≥wny przetwarzania zam√≥wienia", extra={
                'order_id': baselinker_order_id,
                'error': str(e)
            })

        return results

# Singleton instance dla globalnego dostƒôpu
_sync_service_instance = None

def get_sync_service() -> BaselinkerSyncService:
    """
    Pobiera singleton instance BaselinkerSyncService
    
    Returns:
        BaselinkerSyncService: Instancja serwisu sync
    """
    global _sync_service_instance
    
    if _sync_service_instance is None:
        _sync_service_instance = BaselinkerSyncService()
        logger.info("Utworzono singleton BaselinkerSyncService")
    
    return _sync_service_instance

# Funkcje pomocnicze
def sync_orders_from_baselinker(sync_type: str = 'manual_trigger') -> Dict[str, Any]:
    """Helper function dla synchronizacji zam√≥wie≈Ñ"""
    return get_sync_service().sync_orders_from_baselinker(sync_type)

def manual_sync_with_filtering(params: Dict[str, Any]) -> Dict[str, Any]:
    """Helper function dla rƒôcznej synchronizacji z filtrami."""
    return get_sync_service().manual_sync_with_filtering(params)

def update_order_status_in_baselinker(internal_order_number: str) -> bool:
    """Helper function dla aktualizacji statusu"""
    return get_sync_service().update_order_status_in_baselinker(internal_order_number)

def get_sync_status() -> Dict[str, Any]:
    """Helper function dla sprawdzania statusu sync"""
    return get_sync_service().get_sync_status()

def cleanup_old_sync_logs(days_to_keep: int = 30):
    """Helper function dla czyszczenia log√≥w"""
    get_sync_service().cleanup_old_sync_logs(days_to_keep)